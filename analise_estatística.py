# -*- coding: utf-8 -*-
"""Analise_estatística.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14lpGn4ucZuHBldKKF40GWWboRfAiY8QA
"""

!pip install researchpy
!pip install scikit_posthocs
!pip install lifelines
import pandas as pd # DataFrames
import numpy as np # Estatísticas descritivas
from scipy import stats # Análise univariada e de normalidade de dados quantitativos
import researchpy as rp # Qui-quadrado, Fisher, McNemar
from statsmodels.formula.api import ols # ANOVA
import statsmodels.formula.api as smf # Regressão quantílica
import statsmodels.api as sm # ANOVA, Regressão linear, Regressão Logística
from statsmodels.stats.multicomp import pairwise_tukeyhsd #PostHoc Tukey
import scikit_posthocs as sp # PostHoc Conover, PostHoc Dunn
import scikit_posthocs as sp
from sklearn import linear_model # Regressão linear para gráfico
from patsy import dmatrices # Regressão logística
from lifelines import KaplanMeierFitter # Sobrevida
from lifelines import CoxPHFitter # Regressão de Cox
from lifelines.utils import survival_table_from_events # Tabela de Sobrevida
from lifelines.plotting import plot_lifetimes # Curvas de Sobrevida
from lifelines.statistics import logrank_test # Comparação de curvas de sobrevida
from sklearn.metrics import roc_curve, roc_auc_score # Curva ROC
import seaborn as sns # Gráficos
import matplotlib.pyplot as plt
import plotly.express as px
import cufflinks as cf
from plotly.offline import iplot



# Exibir todas as colunas
pd.set_option('display.max_columns', 100)

# from google.colab import drive
# drive.mount('/content/drive')

# Abrir banco de dados em formato csv
df = pd.read_csv('bancomodelo.csv', sep=';')

# Número de linhas e colunas
df.shape

# Exibir primeiras linhas do banco de dados
df.head()

# Exibir informações das variáveis
df.info()

# Exibir nomes das colunas
df.columns

# Contagem de missings
df.isna().sum()

# Percentual de dados omissos
(df.isnull().sum() / len(df['genero']))

# Substituir vírgula por ponto na separação decimal
df['es1'] = df['es1'].apply(lambda x: str(x).replace(',','.'))
df['es2'] = df['es2'].apply(lambda x: str(x).replace(',','.'))
df['creat_pre'] = df['creat_pre'].apply(lambda x: str(x).replace(',','.'))

# Verificar se substutuição deu certo
df.head()

# Converter variáveis para float
df['es1'] = df['es1'].astype('float64')
df['es2'] = df['es2'].astype('float64')
df['creat_pre'] = df['creat_pre'].astype('float64')

# Conferir se conversão deu certo
df.info()

# Imputação de dados quantitativos faltantes

df['es1'].fillna(df['es1'].median(), inplace=True)

df['es2'].fillna(df['es2'].median(), inplace=True)

df['idade'].fillna(df['idade'].mean(), inplace=True)

# Imputação de dados qualitativos
print(df.genero.value_counts())

genero_freq = df.genero.value_counts()[1]

# preencher missing values com o valor acima (1)
df.genero.fillna(genero_freq, inplace=True)

# verificar se há valor ausente
df.genero.isnull().sum()

# Verificação da imputação
df.isna().sum()

# Renomear variável
df = df.rename(columns={'dias inter': 'dias_inter'})

# Renomear categorias de uma variável
df['generoX'] = df.genero.replace({0: 'Feminino', 1: 'Masculino'})

# Verificar alterações
df.columns

# Criar novo data frame apenas com colunas de interesse
df2 = df.loc[:,['genero', 'generoX', 'idade', 'dias_inter', 'dias_obito', 'obito', 'es1', 'es2', 'has', 'dm ', 'dpoc',
       'tabagismo', 'irc', 'creat_pre']]

df2.head()

df2.shape

# Banco de dados com condicionais
# HAS = Sim
# Idade >= 50 anos
# es1 >= 1.0
df3 = df2.loc[(df2['has']== 1) & (df2['idade'] >= 50) & (df2['es1'] >= 1.0)]

df3.shape

# Salvar o arquivo CSV
df.to_csv('bancomodeloedit.csv')

###############################

### Análise de normalidade / Descritiva de Dados Quantitativos ###
df2['creat_pre'].describe()

# SCIPY - STATS
# Intervalo interquartil (IQR)
stats.iqr(df2.creat_pre, nan_policy='omit')

stats.describe(df2.creat_pre)

# Assimetria
stats.skew(df2.creat_pre)

# # Curtose
stats.kurtosis(df2.creat_pre)

# SCIPY - STATS
# Gráfico para verificar se distribuição é normal
fig, ax = plt.subplots()
stats.probplot(df2.creat_pre, fit=True, plot=ax)
plt.title('Gráfico de Probabilidades - Creatinina Pré-Op')
plt.xlabel('Quantiles teóricos')
plt.ylabel('Valores ordenados')
plt.show()

# SCIPY - STATS
# Shapiro-Wilk
stats.shapiro(df2.creat_pre)

# Komolgorov-smirnov
# 1º: Criar objetos para os campos média e desvio padrão
media = np.mean(df2.creat_pre)
dp = np.std(df2.creat_pre, ddof=1)
# 2º: Teste
stats.kstest(df2.creat_pre, cdf='norm', args=(media, dp), N = len(df2.creat_pre))

# Coeficientes de assimetria para todas as variáveis numéricas do banco
df2.select_dtypes(include='number').skew(axis=0,skipna = True)

# Coeficientes de curtose para todas as variáveis numéricas
df2.kurtosis(axis=0,skipna = True)

##########################################

##### ANÁLISE DESCRITIVA ESTRATIFICADA - DADOS QUANTITATIVOS ##########

df2.groupby('genero').agg({'idade':['describe']})

##########################################

##### ANÁLISE DESCRITIVA - DADOS QUALITATIVOS ##########

# Genero
variavel = df2['genero'].value_counts()
mykeys = variavel.keys()
mykeys
myvals = variavel.values
myvals
variavel = pd.DataFrame({'Gênero':mykeys, 'Frequência':myvals})
variavel
variavel['Porcentagem'] = variavel['Frequência']/variavel['Frequência'].sum()*100
variavel

##### ANÁLISE DESCRITIVA ESTRATIFICADA - DADOS QUALITATIVOS ##########

tabela1 = pd.crosstab(index=df2["genero"], columns=df2["has"], margins=True)
print(tabela1)
tabela2 = tabela1/tabela1.loc["All"]
print(tabela2)

#############################
#### TESTE DE PROPORÇÕES ####
#############################

### Qui-quadrado ###
tabela3 = rp.crosstab(df2['genero'], df['has'], margins=True, test='chi-square', expected_freqs=True)
print(tabela3)

### Teste Exato de Fisher ###
tabela3 = rp.crosstab(df2['genero'], df['has'], margins=True, test='fisher', expected_freqs=True)
print(tabela3)

### McNemar (antes / depois) ###
tabela3 = rp.crosstab(df2['has'], df['dpoc'], margins=True, test='mcnemar', expected_freqs=True)
print(tabela3)

#########################################
############## CORRELAÇÕES ##############
#########################################

# Pearson
x = df2.idade
y = df2.es1
stats.pearsonr(x, y)

# Spearman
x = df2.idade
y = df2.es2
stats.spearmanr(x, y)

# Tau de Kendall
x = df2.irc
y = df2.obito
stats.kendalltau(x, y)

#############################################
###### Análise de Dados Quantitativos #######
#############################################

####### Teste T para Amostras Independentes ##########

# Grupos (fator de estratificação)
feminino = df2[df2['genero'] == 0]
masculino = df2[df2['genero'] == 1]

# Teste de Levene (avaliação da hemocedasticidade)
stats.levene(feminino.idade, masculino.idade)

# Descritiva stratificada
df2.groupby('genero').agg({'idade':[np.size, np.mean, np.std]})

# Teste T Amostras Independentes
stats.ttest_ind(feminino['idade'],masculino['idade'], equal_var = True)

################################################
######## Teste T para Uma Amostra ##############
######## Comparação com média populacional #####
################################################

stats.ttest_1samp(df2.idade, 72.0)

################################################################################
####### Mann-Whitney (Análogo não-paramétrico do Teste T independente) #########
################################################################################

# Grupos (fator de estratificação)
feminino = df2[df2['genero'] == 0]
masculino = df2[df2['genero'] == 1]

# Descritiva estratificada
df2.groupby('genero').agg({'creat_pre':[np.size, np.median, stats.iqr]})

stats.mannwhitneyu(feminino.creat_pre, masculino.creat_pre, use_continuity = True, alternative='two-sided')

############################################
###### Teste T para amostras pareadas ######
############################################

# Obs: utilizado es1 e es2 para fins práticos

stats.ttest_rel(df2.es1, df2.es2, nan_policy='omit')

########### Wilcoxon Signed Rank - Pareado Não Paramétrico ##########
### creat_pre utilizada apenas para demonstração, pois se utiliza a diferença antre as variáveis antes / depois ###

stats.wilcoxon(df2.creat_pre, zero_method='wilcox', correction=False, alternative='two-sided', mode='auto')



#################################
##### ANOVA UMA VIA #############
#################################
import statsmodels.formula.api as sm
from statsmodels.stats.anova import anova_lm # Import anova_lm directly
modelo = sm.ols('idade~tabagismo', data = df2).fit()
anova = anova_lm(modelo, type=2)
anova

# Descritiva estratificada
df2.groupby('tabagismo').agg({'idade':[np.size, np.mean, np.std, np.median, stats.iqr]})

##### POST HOC #####
tukey = pairwise_tukeyhsd(endog=df2['idade'], groups=df2['tabagismo'], alpha=0.05)
print(tukey)

###########################
##### ANOVA DUAS VIAS #####
###########################
import statsmodels.formula.api as sm
from statsmodels.stats.anova import anova_lm # Import anova_lm directly
modelo2 = sm.ols('idade~tabagismo+has', data = df2).fit()
anova2 = anova_lm(modelo2, type=2)
anova2

df2.groupby(['tabagismo', 'has'])['idade'].mean()

df2.groupby(['tabagismo', 'has'])['idade'].std()

#########################################################
### Kruskal-Wallis - análogo não paramétrico da ANOVA ###
#########################################################

data = [df2.loc[ids, 'creat_pre'].values for ids in df2.groupby('tabagismo').groups.values()]
k = stats.kruskal(*data)
print(k)

# PostHoc Conover
sp.posthoc_conover(df2, val_col='creat_pre', group_col='tabagismo', p_adjust = 'bonferroni')

# PostHoc Dunn
sp.posthoc_dunn(df2, val_col='idade', group_col='tabagismo', p_adjust = 'bonferroni')

####### REGRESSÃO LINEAR SIMPLES #########

import statsmodels.api as sm
x = df2.idade
y = df2.es1

x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

# Equação de predição do desfecho
# y = m*x+b
# m = coef (0.1027)
# b = intercept (-2.3814)
# y = dependente (euroscore1)
# x = independente (idade)

# Predição do valor do euroScore I  com base na idade (80 anos)
0.1027*80-2.3814

# Gráfico da regressão
x = df2['idade'].values.reshape(-1,1)
y = df2['es1'].values

ols = linear_model.LinearRegression()
model = ols.fit(x, y)
response = model.predict(x)

r2 = model.score(x, y)

plt.style.use('default')
plt.style.use('ggplot')

fig, ax = plt.subplots(figsize=(8, 5))

ax.plot(x, response, color='k', label='Modelo de Regressão')
ax.scatter(x, y, edgecolor='k', facecolor='green', alpha=0.7, label='Dados da Amostra')
ax.set_ylabel('EuroScore 1', fontsize=14)
ax.set_xlabel('Idade', fontsize=14)
ax.text(0.8, 0.1, ' ', fontsize=13, ha='center', va='center',
         transform=ax.transAxes, color='gray', alpha=0.5)
ax.legend(facecolor='white', fontsize=11)
ax.set_title('$R^2= %.2f$' % r2, fontsize=18)

fig.tight_layout()

print(r2)

# Pearson
x = df2.idade
y = df2.es1
stats.pearsonr(x, y)

#### Regressão Linear Múltipla ######

x = df2[['idade', 'creat_pre']]
y = df2.es1
x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

# Equação de predição do desfecho - Regressão multipla
# y = intercept + inclinação1*variável1 + inclinação2*variável2
# 70 anos
# Creat 1.2

y = -1.6515 + (0.1008*70) + (-0.4683*1.2)
print(y)

##### Regressão Logística #####

y, x = dmatrices( 'obito ~ idade + has + creat_pre', data=df2, return_type='dataframe')
mod = sm.Logit(y, x)
res = mod.fit()
res.summary()

print("Coefficients")
print(res.params)
print()
print("p-Values")
print(res.pvalues)
print()
print("Dependent variables")
print(res.model.endog_names)

predictions = res.predict()
print(predictions[0:40])

df2['prob'] = predictions

df2.head()

# Salvar DF2 arquivo CSV
df2.to_csv('df2.csv')

# ODDS RATIO
res_odds=pd.DataFrame(np.exp(res.params), columns=['OR'])

res_odds['Z-Value']=res.pvalues

res_odds[['2.5%', '97.5%']]=np.exp(res.conf_int())

print(res_odds)

# Outra maneira
model = sm.GLM.from_formula("obito ~ idade + has + creat_pre", family=sm.families.Binomial(), data=df2)
result = model.fit()
result.summary()

#### SOBREVIDA #####

# DF sobrevida
dfS = df2.loc[(df2['obito']== 0)]

# Criar objeto Kaplan-Meier Function (kmf)
kmf = KaplanMeierFitter()

# Criar objetivo com variáveis (variáveis apenas para demonstração - HAS como óbito)
dias = dfS.dias_inter
obito = dfS.has

# Agregando dados ao modelo
kmf.fit(dias, obito, label='Kaplan Meier')

# Criando uma estimativa
# CI show = confidence interval
kmf.plot(ci_show=False)

# Curvas para diferentes grupos
# Criar grupos
groups = dfS.genero # Definindo grupos
Feminino = (groups == 0) # Grupo 1
Masculino = (groups == 1) # Grupo 2

# Agregar dados do Grupo 1
kmf.fit(dias[Feminino], obito[Feminino], label='Feminino')
F = kmf.plot(ci_show=False)
kmf.fit(dias[Masculino], obito[Masculino], label='Masculino')
M = kmf.plot(ci_show=False)

cox = CoxPHFitter()

df_cox = dfS.loc[:,['dias_inter', 'has', 'irc', 'tabagismo', 'genero']]
df_cox.head()

cox = CoxPHFitter()
cox.fit(df_cox, 'dias_inter', event_col='has')
cox.print_summary()

table = survival_table_from_events(df['dias_inter'], df['has'])
table

kmf.fit(dias[Feminino], obito[Feminino], label='Feminino')
kmf.survival_function_

kmf.fit(dias[Masculino], obito[Masculino], label='Masculino')
kmf.survival_function_

kmf = KaplanMeierFitter()
kmf.fit(dfS['dias_inter'], event_observed=dfS['has'])
kmf.event_table

#### COMPARAÇÃO DE CURVAS DE EVENTOS #########

feminino=dfS[dfS['genero']== 0]
masculino=dfS[dfS['genero']==1]

tf = feminino['dias_inter']
sf = feminino['has']
tm = masculino['dias_inter']
sm = masculino['has']

kmf = KaplanMeierFitter()

kmf.fit(dias[Feminino], obito[Feminino], label='Feminino')
F = kmf.plot(ci_show=False)
kmf.fit(dias[Masculino], obito[Masculino], label='Masculino')
M = kmf.plot(ci_show=False)

# Log Rank Test
logrank = logrank_test(tf, tm, event_observed_A=sf, event_observed_B=sm)
logrank.print_summary()

####### ROC CURVE #########

a = df2['has']
b = df2['prob']
c = df2['obito'].values

# Linha central (50%)
r_probs = [0 for _ in range(len(c))]

# Cálculo das áreas sob as curvas ROC

print()
r_auc = roc_auc_score(c, r_probs)
print(r_auc)
print()
auc_score = roc_auc_score(a, b)
print(auc_score)

# Curvas ROC
r_fpr, r_tpr, _ = roc_curve(c, r_probs)
auc_fpr, rf_tpr, _ = roc_curve(a, b)

plt.figure(figsize=(8,6))
plt.rcParams.update({'font.size': 15})

plt.plot(r_fpr, r_tpr, marker='_', color = 'black')
plt.plot(auc_fpr, rf_tpr, marker='.', label='AUC = %0.3f)' % auc_score, color = 'blue')
plt.title('Curva ROC', fontsize = 19)
plt.xlabel('Taxa de Falsos-Positivos', fontsize = 18, color = 'black')
plt.ylabel('Taxa de Verdadeiros-Positivos', fontsize = 18, color = 'black')
plt.legend(loc = 0)
plt.show()

# ROC Teste 2
c = df2['obito'].values
d = df2['es1'].values
e = df2['es2'].values

# Linha central (50%)
r_probs = [0 for _ in range(len(c))]

# Cálculo das áreas sob as curvas ROC

print()
r_auc = roc_auc_score(c, r_probs)
print(r_auc)
print()
auc_score2 = roc_auc_score(c, d)
print(auc_score2)
print()
auc_score3 = roc_auc_score(c, e)
print(auc_score3)
print()



r_fpr, r_tpr, _ = roc_curve(c, r_probs)
es1_fpr, es1_tpr, _ = roc_curve(c, d)
es2_fpr, es2_tpr, _ = roc_curve(c, e)

plt.figure(figsize=(10,8))
plt.rcParams.update({'font.size': 15})

plt.plot(r_fpr, r_tpr, marker='_', color = 'black')
plt.plot(es1_fpr, es1_tpr, marker='.', label='AUC ES1 = %0.3f)' % auc_score2, color = 'green')
plt.plot(es2_fpr, es2_tpr, marker='.', label='AUC ES2 = %0.3f)' % auc_score3, color = 'blue')
plt.title('Curvas ROC', fontsize = 19)
plt.xlabel('Taxa de Falsos-Positivos', fontsize = 18, color = 'black')
plt.ylabel('Taxa de Verdadeiros-Positivos', fontsize = 18, color = 'black')
plt.text(0.7, 0.15, 'p = 0.345', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)
plt.legend(loc = 4)
plt.show()

########## DE LONG TEST ##############

import numpy as np
from matplotlib import pyplot as plt
import scipy.stats as st
from sklearn import metrics

def auc(X, Y):
    return 1/(len(X)*len(Y)) * sum([kernel(x, y) for x in X for y in Y])
def kernel(X, Y):
    return .5 if Y==X else int(Y < X)
def structural_components(X, Y):
    V10 = [1/len(Y) * sum([kernel(x, y) for y in Y]) for x in X]
    V01 = [1/len(X) * sum([kernel(x, y) for x in X]) for y in Y]
    return V10, V01

def get_S_entry(V_A, V_B, auc_A, auc_B):
    return 1/(len(V_A)-1) * sum([(a-auc_A)*(b-auc_B) for a,b in zip(V_A, V_B)])
def z_score(var_A, var_B, covar_AB, auc_A, auc_B):
    return (auc_A - auc_B)/((var_A + var_B - 2*covar_AB)**(.5))

# ES1 vs. ES2 - Óbito
actual = df2['obito']
preds_A = df2['es1']
preds_B = df2['es2']

def group_preds_by_label(preds, actual):
    X = [p for (p, a) in zip(preds, actual) if a]
    Y = [p for (p, a) in zip(preds, actual) if not a]
    return X, Y

X_A, Y_A = group_preds_by_label(preds_A, actual)
X_B, Y_B = group_preds_by_label(preds_B, actual)

V_A10, V_A01 = structural_components(X_A, Y_A)
V_B10, V_B01 = structural_components(X_B, Y_B)

auc_A = auc(X_A, Y_A)
auc_B = auc(X_B, Y_B)

# Compute entries of covariance matrix S (covar_AB = covar_BA)
var_A = (get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1/len(V_A10)
         + get_S_entry(V_A01, V_A01, auc_A, auc_A) * 1/len(V_A01))
var_B = (get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1/len(V_B10)
         + get_S_entry(V_B01, V_B01, auc_B, auc_B) * 1/len(V_B01))
covar_AB = (get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1/len(V_A10)
            + get_S_entry(V_A01, V_B01, auc_A, auc_B) * 1/len(V_A01))

# Two tailed test
z = z_score(var_A, var_B, covar_AB, auc_A, auc_B)
p = stats.norm.sf(abs(z))*2

print(z)
print()
print(p)

######### REGRESSÃO QUANTÍLICA ##########

# Variável dependente se afasta da distribuição normal

mod = smf.quantreg('es2 ~ idade + es1', df2)
res = mod.fit(q=.5)
print(res.summary())

#### REGRESSÃO LINEAR #### COMPARAÇÃO
import statsmodels.api as sm
x = df2[['idade', 'es1']]
y = df2.es2
x2 = sm.add_constant(x)
est = sm.OLS(y, x2)
est2 = est.fit()
print(est2.summary())

df2.columns

### BOX PLOT

plt.figure(figsize=(12,7))
plt.rcParams.update({'font.size': 18})

sns.boxplot(x="genero", y="es1", data=df2, palette='light:#5A9')
plt.title('EuroScore 1 vs Gênero', fontsize=18)
plt.xlabel('', fontsize=18)
plt.ylabel('EuroScore I (%)', fontsize=18, color='black')
plt.xticks([0, 1], ['Feminino', 'Masculino'], color='black')
plt.text(0.075, 0.83, 'p = 0.345', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

# plt.savefig('boxplot.pdf', format='pdf', dpi=300, transparent=True, bbox_inches='tight')

plt.figure(figsize=(12,7))

sns.kdeplot(
   data=df2, x="es1", hue="generoX",
   fill=True, common_norm=False, palette="ch:s=.25,rot=-.25",
   alpha=.5, linewidth=0,
)

plt.title('Gráfico de Densidade - EuroScore I', fontsize=20)
plt.xlabel('EuroScore II', fontsize=20)
plt.ylabel('Densidade', fontsize=20)
plt.xticks([0, 2,5, 5, 7.5, 10, 12.5, 15, 17.5, 20])
plt.yticks([0, 0.05, 0.1, 0.15, 0.2])


plt.grid(True)

# plt.savefig('densityplot.pdf', format='pdf', dpi=300, transparent=True, bbox_inches='tight')

# Gráfico de densidades

plt.figure(figsize=(12,7))
plt.rcParams.update({'font.size': 18})

sns.kdeplot(data=df2, x="es1", y="es2", hue="generoX")
plt.title('Gráfico de Densidade', fontsize=20)
plt.xlabel('EuroScore I', fontsize=20, color = 'black')
plt.ylabel('EuroScore II', fontsize=20, color = 'black')

plt.xticks([0, 5, 10, 15, 20, 25, 30, 35])
plt.yticks([0, 2.5, 5, 7.5, 10, 12.5])

plt.grid(True)

#plt.savefig('densityplot.pdf', format='pdf', dpi=300, transparent=True, bbox_inches='tight')

# Gráfico de dispersão

plt.figure(figsize=(12,7))
plt.rcParams.update({'font.size': 18})

sns.scatterplot(data=df2, x="es1", y="es2", hue="generoX", s=180)
sns.rugplot(data=df2, x="es1", y="es2", hue="generoX")
plt.title('Gráfico de Dispersão - Escores de Risco', fontsize=20)
plt.xlabel('EuroScore I', fontsize=20, color='black')
plt.ylabel('EuroScore II', fontsize=20, color='black')

#plt.savefig('densityplot.pdf', format='pdf', dpi=300, transparent=True, bbox_inches='tight')

plt.figure(figsize=(12,7))
plt.rcParams.update({'font.size': 18})

sns.set_theme(style="ticks")
g = sns.catplot(x="generoX", y="es1", hue="has", data=df2, s=7)

plt.xticks(rotation='horizontal', fontsize=15)

plt.title('Gráfico de Dispersão - EuroScore I', fontsize=16)
plt.xlabel('', fontsize=15)
plt.ylabel('EuroScore I', fontsize=16)

#plt.savefig('densityplot.pdf', format='pdf', dpi=300, transparent=True, bbox_inches='tight')

# BarPlot

plt.rcParams.update({'font.size': 12})
plt.figure(figsize=(12,7))

labels = ['AVC', 'IAM', 'Reop', 'Sepse', 'Óbito']
na = [2.5, 3.1, 5.1, 8.1, 8.8]
a = [6.3, 8.2, 7.9, 16.7, 10.1]

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots()
rects1 = ax.bar(x - width/2, na, width, label='Não Anêmico')
rects2 = ax.bar(x + width/2, a, width, label='Anêmico')

# Add some text for labels, title and custom x-axis tick labels, etc.
plt.title('Mortalidade Hospitalar vs Anemia', fontsize=14)
plt.xlabel('Desfechos', fontsize=13)
plt.ylabel('Mortalidade Hospitalar (%)', fontsize=13)
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate('{}'.format(height),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')


autolabel(rects1)
autolabel(rects2)

plt.yticks([0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20])

plt.grid(False)

# plt.savefig('barplot1.pdf', format='pdf', dpi=300, transparent=True, bbox_inches='tight')

df2.head(1)
